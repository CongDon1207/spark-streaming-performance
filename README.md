# Spark Streaming Performance Demo

## ğŸ“‹ Tá»•ng quan dá»± Ã¡n
Demo vá» hiá»‡u suáº¥t Spark Streaming vá»›i cÃ¡c ká»¹ thuáº­t tá»‘i Æ°u hÃ³a vÃ  xá»­ lÃ½ bottleneck. Bao gá»“m 3 phase demo minh há»a tá»« baseline â†’ bottleneck â†’ optimization, cÃ¹ng vá»›i cÃ¡c bÃ i táº­p thá»±c hÃ nh.

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c
```
nhom10/
â”œâ”€â”€ ğŸ“„ README.md                    # TÃ i liá»‡u hÆ°á»›ng dáº«n
â”œâ”€â”€ ğŸ“„ AGENTS.md                    # Quy táº¯c cho AI agents
â”œâ”€â”€ ğŸ“„ docker-compose.yml           # Container orchestration
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Custom Spark image
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“ demo/                        # Demo Performance (Slides 18-26)
â”‚   â”œâ”€â”€ ğŸ phase1_baseline.py       # Phase 1: Baseline (BI=2s, cores=4)
â”‚   â”œâ”€â”€ ğŸ phase2_slow_map.py       # Phase 2: Bottleneck (thÃªm sleep)
â”‚   â”œâ”€â”€ ğŸ phase3_parallelism.py    # Phase 3: Tá»‘i Æ°u (cores=8)
â”‚   â”œâ”€â”€ ğŸ socket_source.py         # Socket server táº¡o dá»¯ liá»‡u test
â”‚   
â”‚
â”œâ”€â”€ ğŸ“ spark/                       # Cáº¥u hÃ¬nh Spark
â”‚   â””â”€â”€ ğŸ“„ spark-defaults.conf      # Spark configuration settings
â”‚
â”œâ”€â”€ ğŸ“ exercises/                   # BÃ i táº­p thá»±c hÃ nh (Slides 27-31)
â”‚  
â”‚
â”œâ”€â”€ ğŸ“ docs/                        # TÃ i liá»‡u thuyáº¿t trÃ¬nh
â”‚   â””â”€â”€ ğŸ“„ ná»™i dung thuyáº¿t trÃ¬nh.docx
â”‚
â””â”€â”€ ğŸ“ scripts/ (tÃ¹y chá»n)          # Scripts tiá»‡n Ã­ch
    â”œâ”€â”€ ğŸ”§ run_socket_source.sh     # Cháº¡y socket source
    â””â”€â”€ ğŸ”§ run_phase3_demo.sh       # Cháº¡y phase 3 demo
```

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. ğŸ—ï¸ Khá»Ÿi Ä‘á»™ng mÃ´i trÆ°á»ng
```bash
# Build vÃ  khá»Ÿi Ä‘á»™ng containers
docker-compose up -d --build

# Kiá»ƒm tra containers Ä‘ang cháº¡y
docker-compose ps
```

### 2. ğŸ¯ Cháº¡y demo performance

> **âš ï¸ LÆ°u Ã½:** Cáº§n cháº¡y socket source trÆ°á»›c khi cháº¡y Spark jobs

#### **Terminal 1: Socket Source (Data Generator)**
```bash
# PowerShell hoáº·c CMD
docker exec -it spark-master python /opt/app/demo/socket_source.py
```
*Giá»¯ terminal nÃ y má»Ÿ - nÃ³ sáº½ sinh dá»¯ liá»‡u liÃªn tá»¥c*

#### **Terminal 2: Spark Streaming Jobs**
```bash
# Phase 1: Baseline (Processing Time < Batch Interval)
docker exec -it spark-master spark-submit --master local[4] /opt/app/demo/phase1_baseline.py

# Phase 2: Bottleneck (Processing Time > Batch Interval) 
docker exec -it spark-master spark-submit --master local[4] /opt/app/demo/phase2_slow_map.py

# Phase 3: Optimized (TÄƒng parallelism Ä‘á»ƒ giáº£m Processing Time)
docker exec -it spark-master spark-submit --master local[8] /opt/app/demo/phase3_parallelism.py
```

### 3. ğŸ“Š Truy cáº­p Spark UI

| Service | URL | MÃ´ táº£ |
|---------|-----|-------|
| **Spark Master UI** | http://localhost:8081 | Quáº£n lÃ½ cluster, workers |
| **Spark Driver UI** | http://localhost:4040 | Monitoring jobs (khi job Ä‘ang cháº¡y) |


### 4. ğŸ“ BÃ i táº­p thá»±c hÃ nh


### **Level 1 â€“ Exercise Fill Gaps (táº¡o delay rá»“i sá»­a)**

**HoÃ n thiá»‡n code** `exercises/exercise_fill_gaps.py` **vÃ ** `exercises/exercise_fix_delay.py` Ä‘á»ƒ giáº£i quyáº¿t yÃªu cáº§u bÃ i táº­p.


#### Má»¥c tiÃªu

* Hiá»ƒu quan há»‡ **Batch Interval (BI)** â€“ **Processing Time (PT)** â€“ **Scheduling Delay**.
* **LÆ°á»£t cháº¡y 1 (táº¡o delay):** cá»‘ tÃ¬nh lÃ m cháº­m â†’ PT > BI â†’ Scheduling Delay tÄƒng.
* **LÆ°á»£t cháº¡y 2 (fix delay):** tÄƒng parallelism/giáº£m táº£i â†’ PT < BI â†’ Scheduling Delay â‰ˆ 0.

#### Chuáº©n bá»‹

* Äáº£m báº£o socket source Ä‘ang cháº¡y:

```bash
docker exec -it spark-master python /opt/app/demo/socket_source.py
# [socket_source] listening on 0.0.0.0:9999
```

* Má»Ÿ **Spark UI** (driver UI hiá»ƒn thá»‹ khi job Ä‘ang cháº¡y):

  * [http://localhost:4040](http://localhost:4040)  (Ä‘á»•i cá»•ng báº±ng `--conf spark.ui.port=4041` náº¿u báº­n)

---

#### **BÆ°á»›c 1 â€” Cháº¡y bÃ i táº¡o delay (Exercise-FillGaps)**

* File: `/opt/app/exercises/exercise_fill_gaps.py`
* Cáº¥u hÃ¬nh chÃ­nh: **BI = 2s**, **sleep = 15ms/record**, **repartition(4)**, **reduceByKey(..., 4)**

Cháº¡y:

```bash
docker exec -it spark-master \
  spark-submit \
  --master local[4] \
  --conf spark.ui.port=4040 \
  /opt/app/exercises/exercise_fill_gaps.py
```

**Quan sÃ¡t trÃªn UI â€º tab *Streaming***

* **Input Rate** ~ 140â€“150 rec/s â‡’ ~280â€“300 rec/batch vá»›i BI=2s.
* **Processing Time (PT)** ~ 1â€“2.5s (tuá»³ mÃ¡y). Náº¿u **PT > 2s** nhiá»u batch liÃªn tiáº¿p:

  * **Scheduling Delay** sáº½ **tÄƒng dáº§n** (Ä‘Æ°á»ng chÃ©o Ä‘i lÃªn).
  * **Queued Batches > 0** (cÃ³ backlog).
* **Total Delay â‰ˆ PT + Scheduling Delay**.

![Before â€“ Streaming Delay](image/streaming_before_delay.png)
> **HÃ¬nh 1 â€“ â€œBeforeâ€:** PT â‰³ BI, Scheduling Delay tÄƒng.

---

#### **BÆ°á»›c 2 â€” Cháº¡y bÃ i fix delay (Exercise-FixDelay)**

* File: `/opt/app/exercises/exercise_fix_delay.py`
* Cáº¥u hÃ¬nh gá»£i Ã½: **BI = 2s**, **sleep = 5ms/record**, **repartition(8)**, **reduceByKey(..., 8)**

Cháº¡y:

```bash
docker exec -it spark-master \
  spark-submit \
  --master local[8] \
  --conf spark.ui.port=4040 \
  /opt/app/exercises/exercise_fix_delay.py
```

**Ká»³ vá»ng trÃªn UI**

* **Processing Time < 2s** rÃµ rá»‡t (thÆ°á»ng ~0.5â€“1.2s tuá»³ mÃ¡y).
* **Scheduling Delay = 0 ms** (Ä‘Æ°á»ng pháº³ng), **Queued Batches = 0**.
* **Total Delay â‰ˆ Processing Time**.

![After â€“ Fixed Delay](image/streaming_after_fix.png)
> **HÃ¬nh 2 â€“ â€œAfterâ€:** PT < BI, Scheduling Delay â‰ˆ 0.

---
